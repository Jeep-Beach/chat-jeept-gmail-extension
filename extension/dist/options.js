var h=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports);var p=h((w,o)=>{(function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const r of document.querySelectorAll('link[rel="modulepreload"]'))s(r);new MutationObserver(r=>{for(const n of r)if(n.type==="childList")for(const a of n.addedNodes)a.tagName==="LINK"&&a.rel==="modulepreload"&&s(a)}).observe(document,{childList:!0,subtree:!0});function t(r){const n={};return r.integrity&&(n.integrity=r.integrity),r.referrerPolicy&&(n.referrerPolicy=r.referrerPolicy),r.crossOrigin==="use-credentials"?n.credentials="include":r.crossOrigin==="anonymous"?n.credentials="omit":n.credentials="same-origin",n}function s(r){if(r.ep)return;r.ep=!0;const n=t(r);fetch(r.href,n)}})();let l=class{constructor(){this.syncKeys=["apiKey","tone","fallbackMessage","useGmailApi"]}async getSyncData(){return new Promise(e=>{chrome.storage.sync.get(this.syncKeys,t=>{e(t)})})}async setSyncData(e){return new Promise(t=>{chrome.storage.sync.set(e,()=>{t()})})}async getLocalData(e){return new Promise(t=>{chrome.storage.local.get(e,s=>{t(s)})})}async setLocalData(e){return new Promise(t=>{chrome.storage.local.set(e,()=>{t()})})}getDefaultSettings(){return{apiKey:"",tone:"friendly, concise, cheerful + helpful",fallbackMessage:`Thanks for reaching out! We are currently experiencing a high level of inbound questions so we would really appreciate it if you could check out FAQs for answers: https://jeepbeach.com/faq/
If you still need help, just reply here and we'll jump in!`,useGmailApi:!1}}async initializeSettings(){const e=await this.getSyncData(),t=this.getDefaultSettings();if(this.syncKeys.some(r=>e[r]===void 0)){const r={...t,...e};return await this.setSyncData(r),r}return e}async getSiteCache(){return(await this.getLocalData(["jeepBeachCache"])).jeepBeachCache||null}async setSiteCache(e){const t={text:e,updatedAt:Date.now()};await this.setLocalData({jeepBeachCache:t})}isCacheExpired(e){if(!e||!e.updatedAt)return!0;const t=4*60*60*1e3;return Date.now()-e.updatedAt>t}};typeof o<"u"&&o.exports?o.exports=l:window.StorageManager=l;let u=class{constructor(e,t="openai"){this.apiKey=e,this.provider=t,this.baseUrl=this.getBaseUrl(t)}getBaseUrl(e){switch(e){case"openai":return"https://api.openai.com/v1";case"anthropic":return"https://api.anthropic.com/v1";default:return"https://api.openai.com/v1"}}async generateDraft(e,t,s,r,n=null){if(!this.apiKey)throw new Error("API key not configured");const a=this.buildSystemPrompt(!!n),d=this.buildUserPrompt(e,t,s,r,n);try{const c=await this.callLLM(a,d);return this.extractDraftFromResponse(c)}catch(c){throw console.error("LLM generation error:",c),c}}buildSystemPrompt(e=!1){return e?`You are a helpful support assistant rewriting email replies to be more user-friendly and professional.
STRICT RULES:
- Preserve the core message and intent of the original text.
- Make it sound warm, friendly, and thoughtful - like a real human wrote it.
- Keep the same factual content but improve tone, clarity, and friendliness.
- Maintain brevity (2–4 sentences) unless more detail is warranted.
- Remove any harsh, terse, or cold language.
- Add appropriate empathy and understanding where it fits naturally.
- Don't add information that wasn't in the original message.`:`You are a helpful support assistant drafting replies for Jeep Beach emails.
STRICT RULES:
- Use ONLY information grounded in the provided JeepBeach snippets.
- If the answer isn't present, use the provided fallback pattern.
- Keep the reply concise (2–4 sentences), friendly, and helpful.
- Do not invent dates, prices, policies, or guarantees.
- End with one human contact path: "If you need a hand, reply here."`}buildUserPrompt(e,t,s,r,n=null){return n?`Email they sent:
---
${e}
---

Draft response to rewrite:
---
${n}
---

Desired tone: ${s}

Rewrite the draft response to be more ${s}, friendly, and professional. Use the email context ONLY to understand what's being discussed so you can make the grammar and phrasing natural (e.g., "No we don't have those events" vs generic "I must decline").

Rules:
- Keep the SAME meaning and answer from the draft
- Make it sound warm and human
- Don't change what the draft is saying - just improve how it's said
- Don't add new information that wasn't in the original draft
- Use the context to make phrasing specific and natural, not generic

Return only the rewritten text.`:`Email to reply to:
---
${e}
---

JeepBeach site knowledge (snippets):
---
${t}
---

Tone: ${s}

Write a short reply grounded ONLY in the snippets above. If nothing relevant, use the fallback pattern:
"${r}"
Return only the email body, no greetings/headers unless the email clearly expects it.`}async callLLM(e,t){var n;const s=this.buildRequestBody(e,t),r=await fetch(`${this.baseUrl}/chat/completions`,{method:"POST",headers:{Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},body:JSON.stringify(s)});if(!r.ok){const a=await r.json().catch(()=>({}));throw new Error(`LLM API error: ${r.status} - ${((n=a.error)==null?void 0:n.message)||r.statusText}`)}return await r.json()}buildRequestBody(e,t){switch(this.provider){case"openai":return{model:"gpt-4o-mini",messages:[{role:"system",content:e},{role:"user",content:t}],max_tokens:250,temperature:.5};case"anthropic":return{model:"claude-3-haiku-20240307",max_tokens:250,temperature:.5,system:e,messages:[{role:"user",content:t}]};default:return{model:"gpt-4o-mini",messages:[{role:"system",content:e},{role:"user",content:t}],max_tokens:250,temperature:.5}}}extractDraftFromResponse(e){var r;if(!e||!e.choices||e.choices.length===0)throw new Error("Invalid LLM response");const t=e.choices[0],s=((r=t.message)==null?void 0:r.content)||t.text||"";if(!s.trim())throw new Error("Empty response from LLM");return s.trim()}async testConnection(){if(!this.apiKey)throw new Error("API key not configured");try{const t=await this.callLLM("You are a helpful assistant.",'Say "Hello, this is a test."');return this.extractDraftFromResponse(t)}catch(e){throw new Error(`LLM test failed: ${e.message}`)}}async getAvailableModels(){if(!this.apiKey)throw new Error("API key not configured");try{const e=await fetch(`${this.baseUrl}/models`,{headers:{Authorization:`Bearer ${this.apiKey}`}});if(!e.ok)throw new Error(`Models API error: ${e.status}`);return(await e.json()).data||[]}catch(e){return console.error("Error fetching models:",e),[]}}};typeof o<"u"&&o.exports?o.exports=u:window.LLMProvider=u;class m{constructor(){this.storage=new StorageManager,this.llmProvider=null,this.init()}async init(){await this.loadSettings(),this.setupEventListeners()}async loadSettings(){try{const e=await this.storage.getSyncData();document.getElementById("apiKey").value=e.apiKey||"",document.getElementById("provider").value=e.provider||"openai",document.getElementById("tone").value=e.tone||"",document.getElementById("fallbackMessage").value=e.fallbackMessage||"",document.getElementById("useGmailApi").checked=e.useGmailApi||!1}catch(e){console.error("Error loading settings:",e),this.showStatus("Error loading settings","error")}}setupEventListeners(){document.getElementById("saveSettings").addEventListener("click",()=>{this.saveSettings()}),document.getElementById("testLLM").addEventListener("click",()=>{this.testLLM()}),document.getElementById("refreshCache").addEventListener("click",()=>{this.refreshCache()}),document.getElementById("resetDefaults").addEventListener("click",()=>{this.resetDefaults()}),document.querySelectorAll("input, textarea, select").forEach(t=>{t.addEventListener("change",()=>{this.saveSettings()})})}async saveSettings(){try{const e={apiKey:document.getElementById("apiKey").value.trim(),provider:document.getElementById("provider").value,tone:document.getElementById("tone").value.trim(),fallbackMessage:document.getElementById("fallbackMessage").value.trim(),useGmailApi:document.getElementById("useGmailApi").checked};if(!e.apiKey){this.showStatus("API key is required","error");return}if(!e.tone){this.showStatus("Tone is required","error");return}if(!e.fallbackMessage){this.showStatus("Fallback message is required","error");return}await this.storage.setSyncData(e),this.showStatus("Settings saved successfully!","success")}catch(e){console.error("Error saving settings:",e),this.showStatus("Error saving settings: "+e.message,"error")}}async testLLM(){const e=document.getElementById("testLLM"),t=e.textContent;try{e.disabled=!0,e.textContent="Testing...";const s=await this.storage.getSyncData();if(!s.apiKey)throw new Error("API key not configured");this.llmProvider=new LLMProvider(s.apiKey,s.provider);const r=await this.llmProvider.testConnection();this.showStatus(`LLM test successful! Response: "${r}"`,"success")}catch(s){console.error("LLM test error:",s),this.showStatus("LLM test failed: "+s.message,"error")}finally{e.disabled=!1,e.textContent=t}}async refreshCache(){const e=document.getElementById("refreshCache"),t=e.textContent;try{e.disabled=!0,e.textContent="Refreshing...";const s=await this.sendMessageToBackground({type:"JB_REFRESH_SITE_CACHE"});if(s.error)throw new Error(s.error);this.showStatus("Content refreshed successfully!","success")}catch(s){console.error("Cache refresh error:",s),this.showStatus("Cache refresh failed: "+s.message,"error")}finally{e.disabled=!1,e.textContent=t}}async resetDefaults(){if(confirm("Are you sure you want to reset all settings to defaults? This will clear your current configuration."))try{const e=this.storage.getDefaultSettings();document.getElementById("apiKey").value=e.apiKey,document.getElementById("provider").value="openai",document.getElementById("tone").value=e.tone,document.getElementById("fallbackMessage").value=e.fallbackMessage,document.getElementById("useGmailApi").checked=e.useGmailApi,await this.storage.setSyncData(e),this.showStatus("Settings reset to defaults!","success")}catch(e){console.error("Error resetting settings:",e),this.showStatus("Error resetting settings: "+e.message,"error")}}showStatus(e,t){const s=document.getElementById("status");s.textContent=e,s.className=`status ${t}`,s.style.display="block",setTimeout(()=>{s.style.display="none"},5e3)}sendMessageToBackground(e){return new Promise(t=>{chrome.runtime.sendMessage(e,s=>{chrome.runtime.lastError?t({error:chrome.runtime.lastError.message}):t(s||{})})})}}document.addEventListener("DOMContentLoaded",()=>{new m})});export default p();
